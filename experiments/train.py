import sys
import os
import argparse
import torch
import torch.nn.functional as F
from torch_geometric.loader import DataLoader
from tqdm import tqdm

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œë¥¼ pathì— ì¶”ê°€í•˜ì—¬ ëª¨ë“ˆ ì„í¬íŠ¸ ê°€ëŠ¥í•˜ê²Œ í•¨
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from models.gnn_solver_v2 import RecurrentGNN
from data.load_dataset import SudokuDataset

def train(model, loader, optimizer, device):
    model.train()
    total_loss = 0
    total_correct = 0
    total_masked_elements = 0
    
    # tqdmìœ¼ë¡œ ì§„í–‰ ìƒí™© ì‹œê°í™”
    pbar = tqdm(loader, desc="Training", unit="batch")
    
    for data in pbar:
        data = data.to(device)
        optimizer.zero_grad()
        
        # Forward Pass
        # x: [Batch * 81, 1], edge_index: [2, E]
        out = model(data.x, data.edge_index) # Output: [Batch * 81, 9]
        
        # Loss Calculation (Masked)
        # íŒíŠ¸ë¡œ ì£¼ì–´ì§„ ìˆ«ì(mask=False)ëŠ” loss ê³„ì‚°ì—ì„œ ì œì™¸í•˜ê³ ,
        # ëª¨ë¸ì´ ë§ì¶°ì•¼ í•  ë¹ˆì¹¸(mask=True)ë§Œ í•™ìŠµí•©ë‹ˆë‹¤.
        mask = data.train_mask
        
        if mask.sum() == 0:
            continue # í˜¹ì‹œë¼ë„ ë¹ˆì¹¸ì´ ì—†ëŠ” ë°ì´í„°ê°€ ìˆë‹¤ë©´ íŒ¨ìŠ¤
            
        # data.yëŠ” 0~8 (ì •ë‹µ ìˆ«ì 1~9ì— ëŒ€ì‘)
        loss = F.cross_entropy(out[mask], data.y[mask])
        
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        
        # Accuracy Calculation (Cell-level)
        pred = out.argmax(dim=1)
        correct = (pred[mask] == data.y[mask]).sum().item()
        total_correct += correct
        total_masked_elements += mask.sum().item()
        
        pbar.set_postfix({'loss': loss.item()})

    avg_loss = total_loss / len(loader)
    avg_acc = total_correct / total_masked_elements if total_masked_elements > 0 else 0
    return avg_loss, avg_acc

@torch.no_grad()
def evaluate(model, loader, device):
    model.eval()
    total_correct = 0
    total_masked_elements = 0
    
    for data in loader:
        data = data.to(device)
        out = model(data.x, data.edge_index)
        
        mask = data.train_mask
        pred = out.argmax(dim=1)
        
        correct = (pred[mask] == data.y[mask]).sum().item()
        total_correct += correct
        total_masked_elements += mask.sum().item()
        
    return total_correct / total_masked_elements if total_masked_elements > 0 else 0

def main():
    parser = argparse.ArgumentParser(description="Train NeuroSudoku GNN Solver")
    parser.add_argument('--batch_size', type=int, default=64, help='Batch size')
    parser.add_argument('--epochs', type=int, default=10, help='Number of epochs')
    parser.add_argument('--lr', type=float, default=0.001, help='Learning rate')
    parser.add_argument('--steps', type=int, default=32, help='Recurrent steps for GNN')
    parser.add_argument('--hidden', type=int, default=96, help='Hidden dimension')
    parser.add_argument('--data_dir', type=str, default='./data', help='Data directory')
    args = parser.parse_args()

    # Device Setup
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸš€ Using device: {device}")

    # Dataset Setup
    # csvê°€ data/raw/sudoku.csvì— ìˆë‹¤ê³  ê°€ì •
    dataset = SudokuDataset(root=args.data_dir, csv_path=os.path.join(args.data_dir, 'raw/sudoku.csv'))
    
    # 9:1 Train/Val Split
    train_size = int(len(dataset) * 0.9)
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])
    
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False)
    
    print(f"ğŸ“Š Dataset: {len(dataset)} total | {len(train_dataset)} train | {len(val_dataset)} val")

    # Model Setup
    model = RecurrentGNN(hidden_dim=args.hidden, num_steps=args.steps).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)

    print("ğŸ”¥ Starting Training...")
    best_val_acc = 0
    
    for epoch in range(1, args.epochs + 1):
        loss, train_acc = train(model, train_loader, optimizer, device)
        val_acc = evaluate(model, val_loader, device)
        
        print(f"Epoch {epoch:02d} | Loss: {loss:.4f} | Train Cell Acc: {train_acc*100:.2f}% | Val Cell Acc: {val_acc*100:.2f}%")
        
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            # ëª¨ë¸ ì €ì¥
            save_path = os.path.join("models", "best_model.pth")
            torch.save(model.state_dict(), save_path)
            print(f"   ğŸ’¾ Best model saved to {save_path}")

if __name__ == "__main__":
    main()